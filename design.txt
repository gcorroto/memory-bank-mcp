Diseño de un Agente de Código (MCP) con “Memory Bank” Integrado
Contexto y Objetivo del Memory Bank
Un Memory Bank en el contexto de un agente de código es, esencialmente, una memoria externa persistente para la IA. Su propósito es permitir que el agente recuerde y entienda el código base completo del proyecto, evitando al máximo la pérdida de contexto y reduciendo al mínimo las alucinaciones en sus respuestas. En otras palabras, actúa como el “cerebro externo” del proyecto: un almacén estructurado donde se guarda conocimiento clave del código, la arquitectura y la documentación, que el agente puede consultar en cualquier momento
medium.com
. Esto garantiza que, aunque la sesión de la IA se reinicie (ya que la memoria interna del modelo es efímera), el agente siempre pueda recuperar el contexto del proyecto desde cero leyendo primero esa información almacenada. Gracias a este enfoque, la IA puede responder preguntas teniendo en cuenta todo el código del usuario y producir nuevas piezas de código consistentes con la base existente, en lugar de respuestas genéricas o desinformadas
simonwillison.net
. En resumen, el objetivo del Memory Bank es dotar al agente de “memoria a largo plazo” sobre el proyecto, para que colabore como un desarrollador que conoce todo el repositorio.
Indexación Semántica del Código Fuente
Para que el agente pueda “recordar” y buscar entre el código, es necesario crear un índice vectorial semántico del repositorio. Esto implica los siguientes pasos fundamentales:
Recorrido e Ignorado Selectivo de Archivos: El agente debe recorrer las carpetas y archivos del workspace o proyecto indicado por el usuario. Durante este proceso, solo se indexarán archivos de código relevantes, ignorando aquellos no útiles para el contexto de programación. Por ejemplo, se pueden excluir archivos binarios, imágenes, dependencias externas voluminosas (como la carpeta node_modules) u otros definidos en un fichero de ignore (un .cursorignore similar a .gitignore). Esta selección garantiza eficiencia y privacidad, evitando procesar datos innecesarios o sensibles.
Chunking (Fragmentación) del Código: Cada archivo de código seleccionado se divide en fragmentos lógicos o “chunks” antes de procesarlo. En lugar de partir simplemente por número de líneas o caracteres, es recomendable fragmentar usando límites semánticos – por ejemplo, por funciones, clases o bloques significativos
read.engineerscodex.com
. Un splitter inteligente (incluso basado en el AST del código) preserva la coherencia de cada fragmento, evitando cortar por la mitad definiciones de funciones o contextos lógicos importantes. Esto mejora la calidad de los embeddings (representaciones vectoriales) al mantener juntos contenidos con sentido completo.
Generación de Embeddings: Por cada fragmento de código, el agente debe obtener un embedding vectorial que capture su significado semántico. Esto típicamente se logra llamando a la API de OpenAI (u otro modelo especializado en código) para convertir el texto del fragmento en un vector numérico. Cursor, por ejemplo, usa su propio modelo de embeddings o la API de OpenAI para esto
read.engineerscodex.com
. Cada vector representa matemáticamente el “contenido” del código, de forma que fragmentos similares tendrán vectores cercanos en el espacio vectorial.
Almacenamiento en el Vector Store: Los embeddings generados se almacenan en una base de datos vectorial (vector store) junto con metadatos útiles. En este caso, el agente agregará a cada vector información como la ruta del archivo de origen y el rango de líneas del fragmento correspondiente. Esto permite luego filtrar resultados por archivo o saber de dónde proviene un fragmento. Un detalle importante es que no es necesario almacenar el texto completo del código en la base de datos, por motivos de privacidad y espacio. De hecho, Cursor no guarda código en texto plano en su servidor; solo guarda los embeddings y rutas ofuscadas, manteniendo el código fuente real solo del lado del cliente
simonwillison.net
simonwillison.net
. En nuestro diseño, dado que el agente opera localmente o en un entorno controlado, podría almacenar fragmentos de código si fuera necesario; pero adoptar la práctica de guardar solo vectores + metadatos es recomendable para seguridad (dificultando reconstruir el código original a partir de los vectores)
simonwillison.net
.
Escalabilidad con Vector DB (ejemplo Turbopuffer): Detrás de escena, este vector store puede ser un servicio especializado. Un ejemplo es Turbopuffer, la solución que utiliza Cursor para escalar su memoria vectorial. Turbopuffer está diseñado para manejar cientos de miles de millones de vectores de forma eficiente y económica
turbopuffer.com
turbopuffer.com
, utilizando almacenamiento en nube (S3) con caché SSD/RAM para conseguir consultas rápidas. Gracias a esta arquitectura, Cursor pudo reducir 20 veces sus costes de búsqueda semántica e indexar más de 100 mil millones de embeddings sin problemas
turbopuffer.com
. En nuestra implementación teórica, podríamos usar Turbopuffer como backend o cualquier base vectorial local/hosted; lo clave es que soporte búsquedas rápidas por similitud y múltiples “namespaces” o índices (por ejemplo, un namespace por proyecto o por usuario, igual que Cursor separa por (user_id, codebase)
turbopuffer.com
).
Actualización Incremental (Merkle Trees): Una vez creado el índice inicial, el agente debe ser capaz de mantenerlo actualizado conforme el código cambie. Cursor resuelve esto calculando un árbol de Merkle de los archivos: un hash jerárquico que detecta qué archivos (o fragmentos) se modificaron desde la última indexación
read.engineerscodex.com
read.engineerscodex.com
. En nuestro agente, podríamos implementar algo similar: por ejemplo, recalcular hashes de archivos periódicamente (o escuchar eventos de guardado) y re-embebeder solo los fragmentos nuevos o cambiados. Esto evita reindexar todo el proyecto innecesariamente y ahorra tiempo y cómputo
read.engineerscodex.com
. Una estrategia más simple si no se usan Merkle trees es confiar en timestamps de modificación de archivos y un registro de qué ya está indexado para actualizar solo lo necesario. Lo importante es que el Memory Bank sea dinámico y refleje la última versión del código.
Herramientas del Agente (Memory Bank Tools)
Para exponer esta funcionalidad al agente de código (MCP), definiremos un conjunto de herramientas especializadas que el agente podrá invocar. Las instrucciones del prompt del agente deberán dejar muy claro cuándo y cómo usar estas herramientas, de forma que siempre que necesite leer o modificar código, lo haga a través del Memory Bank. A continuación, describimos las herramientas principales y las pautas de uso:
Herramienta: IndexarCódigo (Index Workspace/Folder)
Función: Permite al agente indexar semánticamente un directorio completo de proyecto o una carpeta específica. Al invocarla, el agente recorrerá los archivos del directorio indicado (respetando las reglas de ignore mencionadas) y procesará cada archivo mediante chunking y generación de embeddings como se describió. Todos esos vectores y metadatos se almacenarán en el vector store, bajo el namespace correspondiente al proyecto actual.
Cuándo usarla: Siempre que el usuario solicite “memorizar” o “indexar” una carpeta, módulo o todo el workspace. Por ejemplo, si el usuario dice “Indexa esta carpeta” o “Recuerda cómo funciona el módulo X”, el agente debe invocar IndexarCódigo(carpeta=X). También puede usarse al inicio de la sesión en un nuevo proyecto para construir el Memory Bank inicial.
Instrucciones al agente: No asumas nunca que el código ya está en memoria sin haber indexado. Si el usuario no lo ha ordenado explícitamente pero hace una pregunta sobre el código, el agente debería preguntar o proceder a indexar la parte relevante antes de responder. Además, tras modificaciones significativas, podría invocar esta herramienta para actualizar el índice de esa parte del código. La primera vez que se usa, puede ser costosa (muchos archivos), pero luego las actualizaciones serán incrementales. Ejemplo interno: “Usuario pidió memorizar módulo auth/. Voy a llamar a IndexarCódigo("src/auth") para almacenar esos archivos en la memoria vectorial.”
Herramienta: BuscarEnMemoryBank (Semantic Code Search)
Función: Realiza una búsqueda semántica entre los vectores del Memory Bank para encontrar código relevante a una consulta. Internamente, tomará la pregunta o palabra clave dada, generará su embedding (usando la misma técnica de OpenAI u otro modelo), y consultará el vector store para obtener los N fragmentos más similares. Devolverá al agente esos fragmentos de código junto con su ubicación (p.ej. “Archivo utils.py, líneas 30-45”). Esto imita exactamente lo que hace Cursor al responder preguntas sobre el código: “computamos un embedding de la consulta, dejamos que la base vectorial (Turbopuffer) busque los vecinos más cercanos, y obtenemos de vuelta la ruta de archivo y rango de líneas de los mejores matches”, tras lo cual se leen esos archivos localmente
simonwillison.net
.
Cuándo usarla: Debe ser usada cada vez que el usuario haga una pregunta sobre el código o cuando el agente necesite contexto para una tarea. Por ejemplo, si el usuario pregunta “¿Cómo funciona la función X?” o “¿Dónde se define la clase Y?”, el agente invocará BuscarEnMemoryBank("función X") para recuperar los fragmentos relevantes con esa función. También antes de generar código nuevo o refactorizar, el agente debería buscar implementaciones similares para guiar su respuesta. Esto garantiza que las respuestas estén respaldadas por el código real del proyecto. De hecho, con este enfoque la IA puede referenciar implementaciones existentes y mantener consistencia de estilos y patrones del proyecto al proponer código
read.engineerscodex.com
.
Instrucciones al agente: Siempre que respondas sobre la base de código, consulta primero el Memory Bank. No inventes detalles de la implementación sin verificarlos. Usa esta herramienta incluso para preguntas aparentemente sencillas, porque así podrás dar respuestas contextualizadas (por ejemplo, en lugar de responder “creo que la función X hace Y”, el agente podrá decir “en el archivo tal, la función X realiza Y
simonwillison.net
”, proporcionando evidencia concreta). Si la búsqueda no arroja resultados (por ejemplo, la función consultada no está en el índice), considera pedir al usuario que indique el archivo o invoca la herramienta de indexación sobre más partes del código.
Herramienta: LeerArchivo (o acceso controlado a archivos)
Función: Aunque gran parte de las lecturas se resolverán con la búsqueda semántica, puede ser útil una herramienta para abrir un archivo específico por ruta y leer su contenido textual. Esto se usaría si el agente ya sabe exactamente qué archivo necesita (por nombre/ruta) y quiere obtener secciones más amplias o verificar algo concreto. Por ejemplo, tras usar BuscarEnMemoryBank, el agente obtiene “utils.py líneas 10-20” pero tal vez necesita unas líneas adicionales de contexto; podría entonces abrir directamente utils.py y leerlo.
Cuándo usarla: De forma más limitada y siempre después de haber hecho una búsqueda vectorial. Principalmente para obtener contexto adicional cuando los fragmentos del Memory Bank son insuficientes. También si el usuario explícitamente pide ver el contenido completo de un archivo (“Muéstrame el código de X.js”), el agente puede usar LeerArchivo("X.js").
Instrucciones: El agente debe evitar leer archivos enteros innecesariamente (recordemos la ventana de contexto limitada). Mejor usar búsquedas para ubicar relevancia y luego leer solo lo necesario. Además, cualquier lectura debería idealmente actualizar o verificarse contra el índice: si un archivo se lee manualmente y es relevante, el agente podría reindexarlo para futuras consultas. En resumen, esta herramienta es de apoyo, pero la principal vía de obtener información seguirá siendo el Memory Bank semántico.
Herramienta: EscribirArchivo / ModificarCódigo
Función: Permite aplicar cambios en un archivo (por ejemplo, sobreescribir un archivo con contenido modificado o insertar un fragmento). Esta es la herramienta para efectivamente codificar cambios una vez que el agente decide qué hacer.
Cuándo usarla: Después de que el agente haya recopilado el contexto necesario y generado la solución o modificación pedida por el usuario. Por ejemplo, el usuario solicita “Añade una nueva función login() en AuthService”, el agente primero buscará en memory bank cómo es AuthService, qué estilo tiene, etc., luego escribirá la nueva función usando esta herramienta.
Instrucciones: Nunca modificar código sin contexto. Antes de llamar a EscribirArchivo, el agente debe haber obtenido el fragmento existente si va a cambiar algo (usando BuscarEnMemoryBank o LeerArchivo). Esto asegura que no pisa código existente incorrectamente y que entiende el lugar de inserción. Tras la escritura, es aconsejable reindexar ese archivo o módulo para actualizar el Memory Bank (se podría invocar IndexarCódigo solo en ese archivo modificado). Así, el índice sigue coherente con el estado actual del código.
(Además de estas, podrían existir herramientas auxiliares: por ejemplo ResumenDocumento (si se quiere generar un resumen embebible de un archivo extenso en la memoria), o GestionarIgnore para actualizar patrones de exclusión. Sin embargo, las listadas arriba cubren las funciones esenciales.)
Políticas de Uso de las Herramientas de Memoria
Para que el agente realmente se comporte como deseamos, debemos incluir instrucciones claras en su prompt sobre cuándo y cómo usar estas herramientas. Algunas reglas de oro que el agente (MCP) debe seguir constantemente:
1. Carga Inicial de Contexto: Antes de acometer cualquier tarea compleja, el agente debe asegurarse de haber cargado el contexto relevante en memoria. Si la sesión comienza y el usuario no ha solicitado nada aún, el agente podría proactivamente ofrecer indexar el proyecto (“¿Desea que cargue el workspace en mi memoria para ayudarlo mejor?”). Y definitivamente, si el usuario arranca con una pregunta como “¿Qué hace la clase X?” en frío, la respuesta inicial del agente podría ser: “Permíteme indexar el código para buscar esa información…” y proceder a usar IndexarCódigo en la parte necesaria. El agente no debe improvisar una respuesta basada solo en conocimiento general; siempre preferirá obtener la verdad del código del usuario.
2. Búsqueda antes de Responder o Editar: Siempre que el usuario haga una pregunta sobre el funcionamiento de alguna parte del código, o pida un cambio en el código existente, el agente primero realizará una búsqueda en el Memory Bank. Sólo con los resultados en mano formulará su respuesta o plan de acción. Esto imita el comportamiento de Cursor, donde al preguntar algo sobre el código, se traen los fragmentos pertinentes al contexto de la IA
simonwillison.net
. Por ejemplo, si el usuario dice “Explica cómo se calcula el total en OrderService”, el agente usa BuscarEnMemoryBank("OrderService calcular total") y luego responde citando o parafraseando ese código hallado. Si el usuario pide “Refactoriza la función X para hacer Y”, el agente primero recuperará la función X actual para verla antes de proponer cambios. Nunca debe el agente inventar o asumir detalles de implementación sin ver el código real.
3. Minimizar Lectura Directa, Maximizar Búsqueda Semántica: A menos que sea necesario un archivo completo, el agente privilegiará la búsqueda vectorial sobre leer archivos de principio a fin. La búsqueda semántica es mucho más efectiva para encontrar la aguja en el pajar dentro de una gran base de código
simonwillison.net
. Solo en casos puntuales (ej.: el usuario pide “muestra el archivo completo” o la modificación requiere el contexto completo de un archivo) se usará LeerArchivo. Incluso entonces, podría combinarse: por ejemplo, leer solo después de obtener fragmentos para encontrar la posición exacta en el archivo.
4. Persistencia y Sesiones: Debido a que la IA puede “olvidar” entre sesiones, es vital que el Memory Bank sea persistente en disco o base de datos y recargable. Podemos instruir al agente que, al inicio de cada nueva sesión, intente cargar desde el vector store los datos del proyecto actual (si ya existen). Esto se puede hacer manteniendo los embeddings en almacenamiento estable. Adicionalmente, si manejamos un sistema de documentos de memoria (como hacía Cline/Cursor con archivos Markdown en .cursor/memory), el agente debería leerlos siempre al iniciar cualquier trabajo
medium.com
medium.com
. En nuestro diseño, podemos simplificar: al iniciar, si hay un índice vectorial guardado del proyecto, se considera cargado; si no, requerir indexación. El prompt del agente puede aclarar: “Nota: mi memoria de proyecto se restablece cada sesión, por lo que siempre debo recargar el Memory Bank desde almacenamiento o reindexar según convenga”.
5. Confirmación y Feedback: Tras usar herramientas como IndexarCódigo o BuscarEnMemoryBank, el agente debería dar feedback al usuario. Por ejemplo: “He indexado 42 archivos del proyecto. ¿En qué te puedo ayudar ahora con esa información?” o “He encontrado 3 fragmentos relevantes en la base de código, procedo a utilizarlos para la respuesta.” Esto mantiene al usuario informado de que la IA está usando la memoria persistente y garantiza transparencia en la interacción. Además, en caso de que la búsqueda no encuentre nada (p. ej. se buscó una función que no existe en el código), el agente puede preguntar si debe ampliar el índice a otras partes o si quizás hay un error en el nombre buscado.
6. Privacidad y Seguridad: Si bien nuestro agente operará probablemente localmente, vale la pena mencionar buenas prácticas aprendidas de Cursor: evitar subir código propietario a servicios externos innecesariamente. Limitar las llamadas a la API de OpenAI (para embeddings) a fragmentos no sensibles si es posible, o usar modelos locales de embedding. Y como dijimos, no almacenar más código en la nube del necesario. Estas consideraciones pueden plasmarse en las instrucciones como recordatorio de que el Memory Bank debe manejarse de forma segura. (Por ejemplo: “Nunca envíes contenido completo de archivos sensibles al modelo sin autorización explícita; usa embeddings u ofuscación en su lugar”).
Flujo de Trabajo del Agente con Memory Bank – Resumen Final
Para visualizar cómo todo encaja, describamos un flujo típico en que el agente MCP utiliza el Memory Bank tal como lo hace Cursor:
Inicialización/Indexación: El usuario abre un proyecto nuevo en la sesión. El agente ofrece o el usuario solicita: “Indexa el workspace para que puedas ayudarme con el contexto.” El agente entonces invoca IndexarCódigo en la raíz del proyecto. Esto genera embeddings de todos los archivos importantes y los guarda en el vector store (p. ej., usando un namespace único para este proyecto)
turbopuffer.com
. Después de esta operación, la IA informa cuántos archivos o fragmentos fueron indexados exitosamente.
Consulta del Usuario: El usuario pregunta algo, por ejemplo: “¿Dónde se define la variable global MAX_RETRIES y qué valor tiene?”. El agente no recuerda esto de la nada (ni debe confiar en la memoria corta del chat); en su lugar, invoca BuscarEnMemoryBank("MAX_RETRIES"). La búsqueda semántica retorna, digamos, dos fragmentos: uno en config.js donde se define MAX_RETRIES = 5, y otro en retryHandler.js donde se usa. El agente entonces lee esos fragmentos (directamente de los resultados, o abriendo brevemente los archivos en esas líneas)
simonwillison.net
. Con esa información, construye la respuesta: “La constante MAX_RETRIES se define en el archivo config.js con valor 5, y se utiliza en retryHandler.js para limitar los intentos de reconexión.”, citando la evidencia encontrada. El Memory Bank permitió obtener la respuesta exacta basada en el código real, en lugar de una conjetura.
Solicitud de Código/Modificación: Ahora el usuario pide: “Implementa la función reconnect() usando MAX_RETRIES en el módulo de conexión.” El agente procede así: primero busca en la memoria dónde estaría este código: quizá busca BuscarEnMemoryBank("function reconnect") o directamente abre el archivo del módulo de conexión si sabe cuál es. Encuentra que en connection.js hay un esqueleto de reconnect() vacío. Lee el contexto de ese archivo (usando LeerArchivo("connection.js") o similares) para ver cómo debe integrarse la solución (conocer qué importaciones usar, estilo de código, etc.). Luego el agente elabora el código de la función respetando las convenciones del proyecto y usando MAX_RETRIES (sabe su valor por el paso anterior). Finalmente, utiliza la herramienta EscribirArchivo("connection.js", nuevo_contenido) para insertar la implementación de reconnect(). Tras escribir, idealmente reindexa ese archivo: IndexarCódigo("connection.js") para actualizar el embedding de ese fragmento con la implementación nueva. Responde al usuario confirmando: “He añadido la implementación de reconnect() en connection.js, utilizando MAX_RETRIES como solicitado.”.
Sesiones posteriores: Si la sesión se cierra y luego se reabre otro día, el agente puede cargar rápidamente el Memory Bank guardado en disco para no tener que reindexar todo (o reindexar de forma muy rápida gracias a caches de hash/Merkle)
read.engineerscodex.com
read.engineerscodex.com
. Herramientas como Turbopuffer permiten que incluso bases de código enormes permanezcan disponibles de forma eficiente, cargando en memoria solo los índices activos y manteniendo el resto en almacenamiento frío
turbopuffer.com
turbopuffer.com
. Así, el agente siempre “se siente” como si recordara perfectamente todo el proyecto, cuando en realidad está apoyándose en esta infraestructura.
En conclusión, nuestro agente MCP con Memory Bank funciona de manera muy similar a Cursor: indexa el código en vectores semánticos, usa búsquedas vectoriales para traer contexto relevante al responder o generar código, y siempre actualiza/consulta esa memoria externa para brindar respuestas precisas y coherentes con el código del usuario. Con las herramientas e instrucciones descritas, nos aseguramos de que el agente siempre utilice el Memory Bank de forma consistente – es decir, que no intente contestar preguntas de código sin antes revisar la base de conocimiento, y que no modifique archivos sin primero comprender su contenido actual. Este diseño teórico proporciona un marco robusto para un asistente de programación avanzado que aprovecha lo mejor de la IA con contexto extendido, tal como lo hace Cursor en Visual Studio Code con su memoria semántica
simonwillison.net
turbopuffer.com
. Siguiendo esta guía, podemos proceder a implementar las instrucciones finales en el prompt del agente, asegurándonos de incluir todas estas directrices de forma clara para que el comportamiento deseado se cumpla. Fuentes consultadas: La solución se basó en prácticas y datos publicados sobre la herramienta AI Cursor y su sistema de codebase indexing con Memory Bank, incluyendo documentación de seguridad de Cursor
simonwillison.net
simonwillison.net
, análisis técnicos de cómo indexa repositorios
read.engineerscodex.com
read.engineerscodex.com
, artículos que explican la filosofía de Memory Bank como memoria persistente
medium.com
, y la integración con el vector store Turbopuffer para lograr búsquedas semánticas a gran escala
turbopuffer.com
turbopuffer.com
. Estas referencias sustentan las decisiones de diseño aquí expuestas.
Citas

Advanced Cursor: Use the Memory bank to eliminate hallucination | by Malik Chohra | CodeToDeploy | Medium

https://medium.com/codetodeploy/advanced-cursor-use-the-memory-bank-to-eliminate-hallucination-affd3fbeefa3
Cursor: Security

https://simonwillison.net/2025/May/11/cursor-security/

How Cursor Indexes Codebases Fast - by Engineer's Codex

https://read.engineerscodex.com/p/how-cursor-indexes-codebases-fast

How Cursor Indexes Codebases Fast - by Engineer's Codex

https://read.engineerscodex.com/p/how-cursor-indexes-codebases-fast
Cursor: Security

https://simonwillison.net/2025/May/11/cursor-security/
Cursor: Security

https://simonwillison.net/2025/May/11/cursor-security/
Cursor: Security

https://simonwillison.net/2025/May/11/cursor-security/

Cursor scales code retrieval to 100B+ vectors with turbopuffer

https://turbopuffer.com/customers/cursor

Cursor scales code retrieval to 100B+ vectors with turbopuffer

https://turbopuffer.com/customers/cursor

Cursor scales code retrieval to 100B+ vectors with turbopuffer

https://turbopuffer.com/customers/cursor

How Cursor Indexes Codebases Fast - by Engineer's Codex

https://read.engineerscodex.com/p/how-cursor-indexes-codebases-fast

How Cursor Indexes Codebases Fast - by Engineer's Codex

https://read.engineerscodex.com/p/how-cursor-indexes-codebases-fast

How Cursor Indexes Codebases Fast - by Engineer's Codex

https://read.engineerscodex.com/p/how-cursor-indexes-codebases-fast
Cursor: Security

https://simonwillison.net/2025/May/11/cursor-security/

How Cursor Indexes Codebases Fast - by Engineer's Codex

https://read.engineerscodex.com/p/how-cursor-indexes-codebases-fast
Cursor: Security

https://simonwillison.net/2025/May/11/cursor-security/

Advanced Cursor: Use the Memory bank to eliminate hallucination | by Malik Chohra | CodeToDeploy | Medium

https://medium.com/codetodeploy/advanced-cursor-use-the-memory-bank-to-eliminate-hallucination-affd3fbeefa3

Advanced Cursor: Use the Memory bank to eliminate hallucination | by Malik Chohra | CodeToDeploy | Medium

https://medium.com/codetodeploy/advanced-cursor-use-the-memory-bank-to-eliminate-hallucination-affd3fbeefa3

How Cursor Indexes Codebases Fast - by Engineer's Codex

https://read.engineerscodex.com/p/how-cursor-indexes-codebases-fast

Cursor scales code retrieval to 100B+ vectors with turbopuffer

https://turbopuffer.com/customers/cursor

How Cursor Indexes Codebases Fast - by Engineer's Codex

https://read.engineerscodex.com/p/how-cursor-indexes-codebases-fast